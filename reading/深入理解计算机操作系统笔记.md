深入理解计算机系统
第一章计算机系统漫游
本章通过跟踪hello程序的生命周期对系统进行学习。从程序创建-->运行-->输出-->终止，沿着整个程序的生命周期，逐步介绍有关概念，术语和组成。

## 1.1 信息就是位+上下文

源程序实际上是由值0和1组成的位（比特）序列，8个位被组织成一个组，称为字节。
大部分计算机系统都是用ASCII标准来表示文本字符，这种方式实际上就是用一个唯一的单字节大小的整数值印来表示每个字符。
hello.c程序是以字节序列的方式储存在文件中的。每个字节都有一个整数值，对应于某些字符。
hello.c的表示方法说明了一个基本思想:系统中所有的信息--包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。

## 1.2程序被其他程序翻译成不同的格式

为了让程序最终在操作系统上运行，实际上就是设置一个人和计算机沟通的过程。人类可以理解的就是十进制，计算机可以理解的就是二进制，也就是0和1，所以为了让程序可以运行，就需要经过把数字转变为计算机可以识别的二进制。
编译系统:
预处理阶段:预处理器(cpp)根据以字符#开头的命令，修改原始的C程序，生成hello.i的文本文件。
编译阶段:编译器(ccl)将文本文件hello.i翻译成文本文件hello.o，它包含一个汇编语言程序。该程序包含函数main的定义，如下所示
汇编阶段:接下来，汇编器(as)将hello.c翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果存放在目标文件hello.o中。该文件是一个二进制文件。
链接阶段:由于hello程序调用了printf函数，而该函数是一个标准C库中的函数，存在于一个名为printf.o的单独的预编译好的目标文件中，该过程就是把这个文件合并到hello.o中。结果就得到hello文件，它是一个可执行目标文件，可以被加载到内存中，由系统执行。

## 1.3 了解编译系统如何工作是大有益处的

通过编译系统可以将hello.c程序生成正确有成效的机器代码。
编译系统如何工作：
优化程序性能
理解连接时出现的错误
避免安全漏洞

## 1.4 处理器读并解释储存在内存中的指令

编译系统将hello.c源程序被翻译成可执行目标文件hello，并被存放在磁盘上。要想在 Unix系统上运行该可执行文件，我们将它的文件名输入到称为shell的应用程序中∶
linux> ./hello
hello.world
linux>

shell是一个命令行解释器，它输出一个提示符，等待输入一个命令行，然后执行这个命令。
hello程序运行时发生了什么，需要通过计算机典型系统硬件组织来解读
系统的硬件组成：
总线-->携带信息字节并负责在各个部件间传递

I/O设备 -->
I/O(输入/输出)设备是系统与外部世界的联系通道。我们的示例系统包括四个I/O设备:作为用户输入的键盘和鼠标，作为用户输出的显示器，以及用于长期存储数据和程序的磁盘驱动器(磁盘)。最开始，可执行程序hello就存放在磁盘上。

主存-->主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。

处理器：
中央处理单元(CPU)，简称处理器，是执行存储在主存中指令的引擎。处理器组成如下:
- PC:程序计数器，大小为一个字节的存储设备，在任何时刻，PC都指向主存中的某条机器语言指令
- 寄存器文件:是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字
- ALU:算术/逻辑单元，计算新的数据和地址值。
  下面是一些简单操作的例子:

- 加载∶ 从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容。
- 存储∶ 从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容。
- 操作∶把两个寄存器的内容复制到ALU，ALU对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容。
- 跳转∶从指令本身中抽取一个字，并将这个字复制到程序计数器(PC)中，以覆盖 PC中原来的值。
  运行程序的过程----------->>>>>>>>>>

                        ----------->>>>>>>>>>

## 1.5 高速缓存至关重要

当程序加载时，它们被复制到主存;当处理器运行程序时，指令又从主存复制到处理器。这些复制就是开销，减慢了程序"真正"的工作。因此，系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

根据机械设备原理，较大的存储设备要比较小的存储设备运行的慢，而快速设备的造价远高于同类的低速设备。比如说，从磁盘读取一个字节的时间开销要比从主存中读取的开销大1000万倍；处理器从寄存器文件读数据比从主存中读取几乎要快100万倍。
针对这种处理器与主存之间的差异，系统设计者设计出了高速缓存，作为暂时的集结区域。
主要包括:
- L1高速缓存:容量可以达到数万字节，位于处理器芯片上，访问速度几乎和访问寄存器文件一样
- L2高速缓存:容量为数十万到数百万字节，通过一条特殊的总线连接到处理器，进程访问L2高速缓存的时间是L1的5倍
- L3高速缓存:最低级别的缓存，所有内核之间共享
  本书得出的重要结论之一就是，意识到高速缓存存储器存在的应用程序员能够利用高速缓存将程序的性能提高一个数量级。